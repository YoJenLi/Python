{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram是一種統計模型，主要應用在『自然語言處理上』"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用時機：由於字典檔的限制，無法列出一些新的、或特別的術語(例如PTT中的詞彙、或是一些講話的口頭禪)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 馬可夫鏈與N-gram\n",
    "### 簡單來說，就是同類型的事件依序發生的機率。ex:如果昨天是雨天，那麼今天是雨天的機率，會跟昨天是晴天，今天是雨天的機率不同。我們相信天氣現象在時間上有某種連續性，前面發生的狀態會影響到後面發生的狀態，而馬可夫模型就是描述這種前後關係的數學語言。假設只考慮前一天的天氣，為一階馬可夫鏈；把前N天的天氣都納入考慮，就成了N階馬可夫鏈。\n",
    "### 中文的\"字\"是最小單位，也就是n=1。以馬可夫鏈的角度來看，因為前後關係為零，這是一種\"0階馬可夫鏈\"。二字詞\"天氣\"，\"天\"後面接著各種字的機率，構成了n=2，為一種一階馬可夫鏈\n",
    "### 前一個狀態跟下一個狀態的關係。依此類推，我們可以進一步去建立 n=3,4,5… 的統計模型，而這些模型的集合，就是所謂的 n-gram 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs #處理編碼的套件\n",
    "import operator #處理字典檔排序\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cutlist = \"<>/:：;；,、＂’，.。！？｢\\\"\\'\\\\\\n\\r《》“”!@#$%^&*()「」﹖」\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cutSentence(text_path, keywords): #放入原始文章路徑, 增加斷詞的list\n",
    "    \n",
    "    text = codecs.open(text_path,\"r\")\n",
    "    sentence = \"\"\n",
    "    textList = []\n",
    "    \n",
    "    for line in text.readlines():\n",
    "        line = line.strip()\n",
    "        \n",
    "        for keyword in keywords:   #清除關鍵字\n",
    "            line = \"\".join(line.split(keyword))\n",
    "        \n",
    "        for word in line:\n",
    "            if word not in cutlist: #如果文字不是標點符號，就把字加到句子中\n",
    "                sentence += word\n",
    "            else:\n",
    "                textList.append(sentence) #如果遇到標點符號，把句子加到 text list中\n",
    "                sentence = \"\"\n",
    "    return textList   #傳回一個文字陣列       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #第一個參數放處理好的文章(LIST檔，utf-8編碼)，第二個參數放字詞的長度單位，第三個參數放至少要幾次以上\n",
    "def ngram(textLists,n,minFreq):\n",
    "    \n",
    "    words = []\n",
    "    words_freq = {}\n",
    "    result = []\n",
    "    for textList in textLists:\n",
    "        for w in range(len(textList)-(n-1)):#要讀取的長度隨字詞長度改變\n",
    "            words.append(textList[w:w+n]) #抓取長度w-(n-1)的字串\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in words_freq: #如果這個字詞還沒有被放在字典檔中\n",
    "            words_freq[word] = words.count(word) #就開一個新的字詞，裡面放入字詞計算的頻次\n",
    "     \n",
    "    words_freq = sorted(words_freq.items(),key = operator.itemgetter(1),reverse = True)\n",
    "    \n",
    "    for word in words_freq:\n",
    "        if word[1] >= minFreq:\n",
    "            result.append(word)\n",
    "    return result  #回傳一個陣列[詞,頻次]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longTermPriority(path, maxTermLength, minFreq):\n",
    "    longTerms = [] #長詞\n",
    "    longTermsFreq = [] #長詞+次數分配\n",
    "    \n",
    "    for i in range(maxTermLength,1,-1): #字詞數由大至小\n",
    "        text_list = cutSentence(path, longTerms)\n",
    "        \n",
    "        words_freq = ngram(text_list,i,minFreq)\n",
    "        \n",
    "        \n",
    "        for word_freq in words_freq:\n",
    "            longTerms.append(word_freq[0]) #將跑出來的長詞加入 longTerms list 做為下次切割檔案的基礎\n",
    "            \n",
    "            longTermsFreq.append(word_freq) #將長詞和次數加入另外一個list  分成兩個檔儲存的用意是減少迴圈次數\n",
    "    \n",
    "    return longTermsFreq       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空空道人 5\n",
      "士隱聽了 5\n",
      "那僧道 6\n",
      "那道人 5\n",
      "士隱 40\n",
      "雨村 25\n",
      "笑道 17\n",
      "那僧 11\n",
      "不知 10\n",
      "道人 9\n",
      "不過 8\n",
      "一段 8\n",
      "世人 8\n",
      "丫鬟 8\n",
      "弟子 8\n",
      "二人 7\n",
      "有一 7\n",
      "石頭 7\n",
      "了一 7\n",
      "去了 7\n",
      "故事 7\n",
      "風流 7\n",
      "原來 6\n",
      "不可 6\n",
      "神仙 6\n",
      "富貴 6\n",
      "這一 6\n",
      "如此 6\n",
      "聽了 6\n",
      "意欲 6\n",
      "蠢物 6\n",
      "紅塵 6\n",
      "英蓮 6\n",
      "明白 5\n",
      "說著 5\n",
      "心中 5\n",
      "只有 5\n",
      "有些 5\n",
      "封肅 5\n",
      "幾個 5\n",
      "其中 5\n",
      "如今 5\n",
      "之人 5\n",
      "聽得 5\n",
      "之事 5\n",
      "自己 5\n",
      "人都 5\n",
      "不了 5\n",
      "又有 5\n",
      "也不 5\n",
      "下世 5\n",
      "不能 5\n",
      "女子 5\n"
     ]
    }
   ],
   "source": [
    "longTermFreq = longTermPriority(\"text.txt\",6,5) #最長詞6個字、出現頻次5次以上\n",
    "\n",
    "for i in longTermFreq:\n",
    "    print(i[0],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
